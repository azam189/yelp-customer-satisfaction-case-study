{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b315e5-66de-4f53-abaa-d93a3c6a323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script takes previously generated datasets (output_1) and expands them by addi-tional IVs (business_proximity). for the calculation of business_proximity the category 'restaurants' is used for calculations intentionally as every restaurant poses a competi-tor/threat in itself to other restaurants.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from itertools import combinations\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import time\n",
    "start_time = time.time()\n",
    "# set working directory to where python file is located\n",
    "wd = os.path.dirname(os.path.abspath(__file__))\n",
    "os.chdir(wd)\n",
    "def haversine_vectorized(coords):\n",
    "distances = haversine_distances(coords) * 6371 # convert haversine distances to km\n",
    "return distances\n",
    "def compute_category_intersections(group):\n",
    "category_intersections = {}\n",
    "26\n",
    "for i, j in combinations(group.index, 2):\n",
    "categories_i = set(group.at[i, 'categories'].split(', '))\n",
    "categories_j = set(group.at[j, 'categories'].split(', '))\n",
    "intersection = len(categories_i.intersection(categories_j))\n",
    "category_intersections[(i, j)] = intersection\n",
    "category_intersections[(j, i)] = intersection\n",
    "print(f\"Intersection between {i} and {j}: {intersection} categories\")\n",
    "return category_intersections\n",
    "def compute_proximity_within_group(group, distances, category_intersections):\n",
    "proximities = {}\n",
    "for i in group.index:\n",
    "proximity_sum = 0.0\n",
    "categories_x = set(group.at[i, 'categories'].split(', '))\n",
    "BC = len(categories_x)\n",
    "print(f\"\\nCalculating proximity for business {i}, Total categories (BC): {BC}\")\n",
    "for j in group.index:\n",
    "if i != j:\n",
    "BCs = category_intersections.get((i, j), 0)\n",
    "distance = distances[group.index.get_loc(i), group.index.get_loc(j)]\n",
    "if distance != 0:\n",
    "proximity_value = (BCs / BC) / distance\n",
    "proximity_sum += proximity_value\n",
    "print(f\" Compared with business {j}: Shared categories (BCs): {BCs}, Dis-tance: {distance:.2f} km, Proximity: {proximity_value:.5f}\")\n",
    "proximities[i] = proximity_sum\n",
    "print(f\"Total proximity for business {i}: {proximity_sum:.5f}\")\n",
    "return proximities\n",
    "def optimized_proximity_computation(df, grouping_column):\n",
    "# group dataframe by city or postal code\n",
    "grouped = df.groupby(grouping_column)\n",
    "proximity_series = pd.Series(index=df.index, dtype=float)\n",
    "27\n",
    "for name, group in grouped:\n",
    "print(f\"\\nComputing proximites for group: {name}\")\n",
    "# convert latitude and longitude to radians for the group\n",
    "coords = group[['latitude', 'longitude']].apply(np.radians).to_numpy()\n",
    "distances = haversine_vectorized(coords)\n",
    "category_intersections = compute_category_intersections(group)\n",
    "# compute proximity within group\n",
    "group_proximities = compute_proximity_within_group(group, distances, cate-gory_intersections)\n",
    "for index, proximity in group_proximities.items():\n",
    "proximity_series.at[index] = proximity\n",
    "print(f\"Assigned proximity {proximity:.5f} to business {index}\")\n",
    "# assign computed proximites back to df\n",
    "df['business_proximity'] = proximity_series\n",
    "return df\n",
    "def process_state_subset(args):\n",
    "state, subset, grouping_column = args\n",
    "print(f\"Processing state: {state}\")\n",
    "return optimized_proximity_computation(subset, grouping_column)\n",
    "def run_proximity_computation_with_mp(df, grouping_column):\n",
    "# split the df into subsets by state\n",
    "state_groups = {state: subset for state, subset in df.groupby('state')}\n",
    "# prepare arguments for multiprocessing (aka frying my memory)\n",
    "pool_args = [(state, subset.copy(), grouping_column) for state, subset in state_groups.items()]\n",
    "results = []\n",
    "# process every subset in parallel\n",
    "with Pool(mp.cpu_count()) as pool:\n",
    "results_objects = [pool.apply_async(process_state_subset, args=(arg,)) for arg in pool_args]\n",
    "for r in results_objects:\n",
    "try:\n",
    "result = r.get(timeout=300)\n",
    "28\n",
    "results.append(result)\n",
    "except mp.TimeoutError:\n",
    "print(\"Process timed out and was terminated\")\n",
    "# combine results from each subset\n",
    "combined_results = pd.concat(results) if results else pd.DataFrame()\n",
    "return combined_results\n",
    "input_path_main = 'output_1.csv'\n",
    "df = pd.read_csv(input_path_main)\n",
    "new_df = optimized_proximity_computation(df, 'postal_code')\n",
    "df = new_df\n",
    "# Cap outliers to the 99 Percentile\n",
    "business_proximity_99_percentile = df['business_proximity'].quantile(0.99)\n",
    "print(business_proximity_99_percentile)\n",
    "df ['capped_business_proximity'] = df['business_proximity'].apply(lambda x: min(x, business_proximity_99_percentile))\n",
    "# Scaling the Data using RobustScaler from scikit-learn\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "scaler = RobustScaler()\n",
    "# Reshape the Data since scaler requires a 2D array\n",
    "capped_proximity_array = df['capped_business_proximity'].values.reshape(-1, 1)\n",
    "# Fit the scaler to the data and then transform it\n",
    "scaled_capped_proximity = scaler.fit_transform(capped_proximity_array)\n",
    "df['scaled_capped_business_proximity'] = scaled_capped_proximity.flatten()\n",
    "# Save Subplots directly\n",
    "figsize = (16, 9)\n",
    "29\n",
    "# Histogram for the original data\n",
    "plt.figure(figsize=figsize)\n",
    "sns.histplot(df['business_proximity'], kde=True)\n",
    "plt.title('Original Business Proximity')\n",
    "plt.savefig('original_business_proximity.png', dpi=300)\n",
    "# Histogram for the capped data\n",
    "plt.figure(figsize=figsize)\n",
    "sns.histplot(df['capped_business_proximity'], kde=True, color='orange')\n",
    "plt.title('Capped Business Proximity')\n",
    "plt.savefig('capped_business_proximity.png', dpi=300)\n",
    "# Histogram for the scaled capped data\n",
    "plt.figure(figsize=figsize)\n",
    "sns.histplot(df['scaled_capped_business_proximity'], kde=True, color='green')\n",
    "plt.title('Scaled Capped Business Proximity')\n",
    "plt.savefig('scaled_capped_business_proximity.png', dpi=300)\n",
    "# Show all three subplots side by side for comparison and save as compiled figure\n",
    "plt.figure(figsize=(24, 8))\n",
    "# Histogram for the original data\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df['business_proximity'], kde=True)\n",
    "plt.title('Original Business Proximity')\n",
    "# Histogram for the capped data\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df['capped_business_proximity'], kde=True, color='orange')\n",
    "plt.title('Capped Business Proximity')\n",
    "# Histogram for the scaled capped data\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df['scaled_capped_business_proximity'], kde=True, color='green')\n",
    "plt.title('Scaled Capped Business Proximity')\n",
    "plt.tight_layout()\n",
    "plt.savefig('business_proximity_analysis.png', dpi=300)\n",
    "# Show all plots\n",
    "30\n",
    "plt.show()\n",
    "# export data\n",
    "with pd.ExcelWriter('output_2.xlsx') as writer:\n",
    "df.to_excel(writer, sheet_name='sheet_1', index=False)\n",
    "df.to_csv('output_2.csv', index=False)\n",
    "print('--- Runtime: %s seconds ---' % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
